<!-- build time:Sat Nov 04 2023 16:59:33 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="OSAKANA" href="https://osakana373.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="OSAKANA" href="https://osakana373.github.io/atom.xml"><link rel="alternate" type="application/json" title="OSAKANA" href="https://osakana373.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="计算机本科课程"><link rel="canonical" href="https://osakana373.github.io/Undergraduate-computer-course/nlp/%E8%AF%8D%E5%90%91%E9%87%8F/"><title>词向量 - 自然语言处理 - 人工智能 - 计算机本科课程 | OSAKANA = OSAKANA = 一緒に夢を見よう</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">词向量</h1><div class="meta"><span class="item" title="创建时间：2021-11-26 18:09:13"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2021-11-26T18:09:13+08:00">2021-11-26</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>6k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>5 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">OSAKANA</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://s2.loli.net/2023/10/17/41sHVDqpGXJ9fId.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2023/10/17/NaQTivZ1XtCLSEd.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2023/10/17/i3NetwkQEn4vydo.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2023/10/17/kdxv6E3sgahQRlj.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2023/10/17/zNqaQp5gvxMCjFH.jpg"></li><li class="item" data-background-image="https://s2.loli.net/2023/10/17/6VYTuKLQGMydihI.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Undergraduate-computer-course/" itemprop="item" rel="index" title="分类于 计算机本科课程"><span itemprop="name">计算机本科课程</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Undergraduate-computer-course/AI/" itemprop="item" rel="index" title="分类于 人工智能"><span itemprop="name">人工智能</span></a><meta itemprop="position" content="2"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/Undergraduate-computer-course/AI/nlp/" itemprop="item" rel="index" title="分类于 自然语言处理"><span itemprop="name">自然语言处理</span></a><meta itemprop="position" content="3"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://osakana373.github.io/Undergraduate-computer-course/nlp/%E8%AF%8D%E5%90%91%E9%87%8F/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/touxiang.jpg"><meta itemprop="name" content="おうじせん"><meta itemprop="description" content="一緒に夢を見よう, 誰よりスキだから"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="OSAKANA"></span><div class="body md" itemprop="articleBody"><h1 id="实验介绍"><a class="anchor" href="#实验介绍">#</a> 实验介绍</h1><h2 id="实验名称"><a class="anchor" href="#实验名称">#</a> 实验名称</h2><p>自然语言处理第一次实验 -- 词向量的训练与特性及关系可视化</p><h2 id="实验目的"><a class="anchor" href="#实验目的">#</a> 实验目的</h2><ul><li><p>了解分词与词向量的训练。</p><p>分词就是将句子、段落、文章这种长文本，分解为以字词为单位的数据结构，方便后续的处理分析工作。词向量，顾名思义就是用来表示词的向量，也可被认为是词的特征向量或表征。把词映射为实数域向量的技术也叫词嵌入。我们通常在训练语言模型的同时得到词向量。</p></li></ul><p><span id="more"></span></p><ul><li><p>了解 Word2Vec 词向量的特性。</p><p>词向量本质是将一些低维、离散、不带任何意义的序号映射成带有特定任务性质的高维特征。为了研究这些特性，可以显式地通过余弦距离来比较两个词的相似性，也可以通过词间的类比关系来探查词向量的影藏特性，另外还可以通过 PCA 降维的方式将词向量可视化。</p></li></ul><h2 id="实验环境"><a class="anchor" href="#实验环境">#</a> 实验环境</h2><p>python 3 + jieba + gensim + sklearn + matplotlib + NumPy + seaborn</p><ul><li><p>python3</p><p>除了高性能外，拥有 NumPy、SciPy 等优秀的数值计算、统计分析库。TensorFlow、Caffe 等著名的深度学习框架都提供了 Python 接口。</p></li><li><p>jieba</p><p>jieba 是一款优秀的 Python 第三方中文分词库，支持三种分词模式：精确模式、全模式和搜索引擎模式。</p></li><li><p>gensim</p><p>gensim 是一款开源的第三方 Python 工具包，用于从原始的非结构化的文本中，无监督地学习到文本隐层的向量表达。它支持包括 TF-IDF，LSA，LDA，和 word2vec 在内的多种算法。</p></li><li><p>Sklearn</p><p>Sklearn (全称 Scikit-Learn) 是基于 Python 语言的机器学习工具。它建立在 NumPy, SciPy, Pandas 和 Matplotlib 之上，Sklearn 里面有六大任务模块：分别是分类、回归、聚类、降维、模型选择和预处理。</p></li><li><p>Matplotlib</p><p>Matplotlib 是 Python 的绘图库，可与 NumPy 一起使用，提供了一种有效的 MATLAB 开源替代方案。</p></li><li><p>NumPy</p><p>NumPy 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。</p></li><li><p>Seaborn</p><p>Seaborn 是基于 Matplotlib 的图形可视化 Python 包，在 Matplotlib 的基础上进行了更高级的封装，使得作图更加容易。</p></li></ul><h1 id="实验内容"><a class="anchor" href="#实验内容">#</a> 实验内容</h1><h2 id="实验方案设计"><a class="anchor" href="#实验方案设计">#</a> 实验方案设计</h2><ol><li><p>使用 jieba 分词工具进行分词，使用方法：jieba.cut (text);</p><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">seg_list = jieba.cut(<span class="string">&quot;他来到上海交通大学&quot;</span>, cut_all=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;/&quot;</span>.join(seg_list))</span><br></pre></td></tr></table></figure><p></p></li></ol><blockquote><p>他 / 来到 / 上海交通大学</p></blockquote><ol start="2"><li><p>使用 gensim 中的 Word2Vec 模型训练词向量：</p><p>model = Word2Vec (common_texts, size=100, window=5, min_count=1, workers=4)；min_count 指定了需要训练词语的最小出现次数，默认为 5；size 指定了训练时词向量维度，默认为 100；worker 指定了完成训练过程的线程数，默认为 1 不使用多线程。</p></li><li><p>使用训练好的词向量对指定的词（2 个例子）进行相关性比较：model.similarity (' 中国 ',' 中华 ')；</p><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">r&quot;E:\自然语言处理\2021自然语言处理第一次实验\实验一&gt; 数据集.txt&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f1:</span><br><span class="line">   document = f1.read()</span><br><span class="line">   document_cut = jieba.cut(document)</span><br><span class="line">   result = <span class="string">&#x27; &#x27;</span>.join(document_cut)</span><br><span class="line">   <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">r&quot;E:\自然语言处理\2021自然语言处理第一次实验&gt; \lab1_dataset_segment.txt&quot;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f2:</span><br><span class="line">   f2.write(result)</span><br><span class="line"></span><br><span class="line">corpus = <span class="string">r&quot;E:\自然语言处理\2021自然语言处理第一次实验&gt; \lab1_dataset_segment.txt&quot;</span></span><br><span class="line">sentences = word2vec.LineSentence(corpus)</span><br><span class="line">model = word2vec.Word2Vec(sentences, vector_size=<span class="number">100</span>,  window=<span class="number">20</span>, min_count=<span class="number">1</span>)</span><br><span class="line">model.save(<span class="string">r&quot;E:\自然语言处理\2021自然语言处理第一次实验 \word2vec.model&quot;</span>)</span><br><span class="line">model.wv.save_word2vec_format(<span class="string">r&quot;E:\自然语言处理\2021自然语言&gt; 处理第一次实验\w2v.txt&quot;</span>)</span><br><span class="line">r = model.wv.similarity(<span class="string">&#x27;中国&#x27;</span>, <span class="string">&#x27;中华&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p></p><blockquote><p>0.45231482</p></blockquote><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = model.wv.similarity(<span class="string">&#x27;世界&#x27;</span>, <span class="string">&#x27;全球&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p></p><blockquote><p>0.7441377</p></blockquote></li><li><p>使用训练好的词向量选出与指定词（2 个例子）最相似的 5 个词：model.wv.most_similar (positive=[' 武汉 '], topn=5);</p><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line">path = <span class="string">r&#x27;E:\自然语言处理\2021自然语言处理第一次实验\word2vec.model&#x27;</span></span><br><span class="line">wv_model = gensim.models.Word2Vec.load(path)</span><br><span class="line">r = wv_model.wv.most_similar(positive=[<span class="string">&#x27;武汉&#x27;</span>] , topn=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p></p><blockquote><p>[(' 沈阳 ', 0.9188286066055298), (' 成都 ', 0.9137787222862244), (' 郑州 ', 0.8937368392944336), (' 天津 ', 0.8855016827583313), (' 哈尔滨 ', 0.8804143667221069)]</p></blockquote><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = wv_model.wv.most_similar(positive=[<span class="string">&#x27;上海&#x27;</span>] , topn=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p></p><blockquote><p>[(' 深圳 ', 0.8482241034507751), (' 天津 ', 0.8347505927085876), (' 广州 ', 0.8052346110343933), (' 广东 ', 0.7736815810203552), (' 成都 ', 0.7624819874763489)]</p></blockquote></li><li><p>使用训练好的词向量选出与指定词类比最相似的 5 个词（2 个例子），如湖北 - 武汉 + 成都 = 四川： model.wv.most_similar (positive=[' 湖北 ', ' 成都 '], negative=[' 武汉 '], topn=5);</p><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line"><span class="keyword">import</span> gensim</span><br><span class="line">path = <span class="string">r&#x27;E:\自然语言处理\2021自然语言处理第一次实验  \word2vec.model&#x27;</span></span><br><span class="line">wv_model = gensim.models.Word2Vec.load(path)</span><br><span class="line">r = wv_model.wv.most_similar(positive=[<span class="string">&#x27;湖北&#x27;</span>, <span class="string">&#x27;成都&#x27;</span>], negative=[<span class="string">&#x27;武汉&#x27;</span>], topn=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p></p><blockquote><p>[(' 河南 ', 0.8770621418952942), (' 安徽 ', 0.8735557198524475), (' 河北 ', 0.8696352243423462), (' 吉林 ', 0.8685503602027893), (' 湖南 ', 0.8605893850326538)]</p></blockquote><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = wv_model.wv.most_similar(positive=[<span class="string">&#x27;江苏&#x27;</span>, <span class="string">&#x27;长沙&#x27;</span>], negative=[<span class="string">&#x27;南京&#x27;</span>], topn=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(r)</span><br></pre></td></tr></table></figure><p></p><blockquote><p>[(' 黑龙江 ', 0.8322128653526306), (' 吉林 ', 0.8317105174064636), (' 湖北 ', 0.8213458061218262), (' 浙江 ', 0.8065339922904968), (' 辽宁 ', 0.8054839968681335)]</p></blockquote></li><li><p>使用 sklearn 中的 PCA 方法对列表 [' 江苏 ', ' 南京 ', ' 成都 ', ' 四川 ', ' 湖北 ', ' 武汉 ', ' 河南 ', ' 郑州 ', ' 甘肃 ', ' 兰州 ', ' 湖南 ', ' 长沙 ', ' 陕西 ', ' 西安 ', ' 吉林 ', ' 长春 ', ' 广东 ', ' 广州 ', ' 浙江 ', ' 杭州 ']（可换成其他）中的所有词的词向量进行降维并使用 seaborn 和 matplotlib 将其可视化：</p><p></p><figure class="highlight python"><figcaption><span>python</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">embeddings = wv_model.wv[<span class="string">&#x27;江苏&#x27;</span>, <span class="string">&#x27;南京&#x27;</span>, <span class="string">&#x27;四川&#x27;</span>, <span class="string">&#x27;湖北&#x27;</span>, <span class="string">&#x27;武汉&#x27;</span>,\</span><br><span class="line"><span class="string">&#x27;河南&#x27;</span>, <span class="string">&#x27;郑州&#x27;</span>, <span class="string">&#x27;甘肃&#x27;</span>, <span class="string">&#x27;湖南&#x27;</span>, <span class="string">&#x27;长沙&#x27;</span>, <span class="string">&#x27;石家庄&#x27;</span>,\</span><br><span class="line"><span class="string">&#x27;陕西&#x27;</span>, <span class="string">&#x27;西安&#x27;</span>, <span class="string">&#x27;吉林&#x27;</span>, <span class="string">&#x27;长春&#x27;</span>, <span class="string">&#x27;广东&#x27;</span>, <span class="string">&#x27;广州&#x27;</span>, <span class="string">&#x27;浙江&#x27;</span>, <span class="string">&#x27;杭州&#x27;</span>]</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">results = pca.fit_transform(embeddings)</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] =<span class="literal">False</span></span><br><span class="line">x = results[:,<span class="number">0</span>]</span><br><span class="line">y = results[:,<span class="number">1</span>]</span><br><span class="line">label = [<span class="string">&#x27;江苏&#x27;</span>, <span class="string">&#x27;南京&#x27;</span>, <span class="string">&#x27;四川&#x27;</span>, <span class="string">&#x27;湖北&#x27;</span>, <span class="string">&#x27;武汉&#x27;</span>,\</span><br><span class="line"><span class="string">&#x27;河南&#x27;</span>, <span class="string">&#x27;郑州&#x27;</span>, <span class="string">&#x27;甘肃&#x27;</span>, <span class="string">&#x27;湖南&#x27;</span>, <span class="string">&#x27;长沙&#x27;</span>, <span class="string">&#x27;石家庄&#x27;</span>,\</span><br><span class="line"><span class="string">&#x27;陕西&#x27;</span>, <span class="string">&#x27;西安&#x27;</span>, <span class="string">&#x27;吉林&#x27;</span>, <span class="string">&#x27;长春&#x27;</span>, <span class="string">&#x27;广东&#x27;</span>, <span class="string">&#x27;广州&#x27;</span>, <span class="string">&#x27;浙江&#x27;</span>, <span class="string">&#x27;杭州&#x27;</span>]</span><br><span class="line"><span class="comment">#sns.scatterplot(x=results[:,0],y=results[:,1],   &gt; size=label)</span></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">   plt.annotate(label[i], xy = (x[i], y[i]), xytext = (x[i]+<span class="number">0.2</span>, y[i]-<span class="number">0.1</span>)) </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p></li></ol><p><img data-src="nlp_lab1_result.png" alt></p><h2 id="实验结果分析"><a class="anchor" href="#实验结果分析">#</a> 实验结果分析</h2><p>word2vec 是从大量文本中以无监督学习的方式学习语义知识模型，其本质就是通过学习文本来用词向量的方式表征词的义信息，通过嵌入空间将语义上相似的单词映射到距离相近地方。即将单词从原先所属的空间映射到新的多维空间中。<br>我们通过 word2vec 算法训练数据集中的词向量，并对指定词行比较，得出相似率和最相似的 n 个词；也能够通过设 positive 和 negative 参数得出与指定词类最相似的 n 个词。<br>使用 matplotlib 对列表中的词向量进行降维并实现可视化。</p><h1 id="实验总结"><a class="anchor" href="#实验总结">#</a> 实验总结</h1><p>通过本次实验，我对 jieba 分词，词向量以及使用 word2vec 进行词向量的训练有了比较清晰的认识和使用。</p><h2 id="jieba分词"><a class="anchor" href="#jieba分词">#</a> jieba 分词</h2><p>jieba 支持三种分词模式</p><ul><li>精确分词：试图将句子最精确的切开，适合文本分析。</li><li>全模式：把句子中所有的可以成词的词语都扫描出来，速度非常快，但是不能解决歧义。</li><li>搜索引擎模式：在精确模式基础上，对长词进行再次切分，提高 recall，适合于搜索引擎。</li></ul><p>对于本实验中使用的函数 jieba.cut：<br>jieba.cut 返回一个可迭代的 generator，可以使用 for 循环来获得分词后得到的每一个词语 (也可以用 jieba.lcut 直接返回分词 list 结果)。</p><ul><li>cut_all=True, HMM=_对应于全模式，即所有在词典中出现的词都会被切分出来，实现函数为__cut_all；</li><li>cut_all=False, HMM=False 对应于精确模式且不使用 HMM；按 Unigram 语法模型找出联合概率最大的分词组合，实现函数为__cut_DAG；</li><li>cut_all=False, HMM=True 对应于精确模式且使用 HMM；在联合概率最大的分词组合的基础上，HMM 识别未登录词，实现函数为__cut_DAG_NO_HMM。</li></ul><h2 id="word2vec"><a class="anchor" href="#word2vec">#</a> Word2Vec</h2><p>使用 gensim 中的 Word2Vec 模型训练词向量：model = Word2Vec (common_texts, size=100, window=5, min_count=1, workers=4)；min_count 指定了需要训练词语的最小出现次数，默认为 5；size 指定了训练时词向量维度，默认为 100；worker 指定了完成训练过程的线程数，默认为 1 不使用多线程。</p><h2 id="pca"><a class="anchor" href="#pca">#</a> PCA</h2><p>使用 pca = PCA (n_components=2)；results = pca.fit_transform (embeddings) 对高维数据进行降维（降至二维，便于可视化）。使用 matplotlib.pyplot 对降维后的数据进行可视化。</p><div class="tags"><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/" rel="tag"><i class="ic i-tag"></i> 计算机本科课程</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2021-12-14 01:11:02" itemprop="dateModified" datetime="2021-12-14T01:11:02+08:00">2021-12-14</time> </span><span id="Undergraduate-computer-course/nlp/词向量/" class="item leancloud_visitors" data-flag-title="词向量" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="おうじせん 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="おうじせん 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>おうじせん <i class="ic i-at"><em>@</em></i>OSAKANA</li><li class="link"><strong>本文链接：</strong> <a href="https://osakana373.github.io/Undergraduate-computer-course/nlp/%E8%AF%8D%E5%90%91%E9%87%8F/" title="词向量">https://osakana373.github.io/Undergraduate-computer-course/nlp/词向量/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC96aC1DTg=="><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"></div><div class="item right"><a href="/2021%E5%B9%B411%E6%9C%8829%E6%97%A5/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;s2.loli.net&#x2F;2023&#x2F;10&#x2F;17&#x2F;6VYTuKLQGMydihI.jpg" title="2021年11月29日"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 生活随笔</span><h3>2021年11月29日</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">实验介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E5%90%8D%E7%A7%B0"><span class="toc-number">1.1.</span> <span class="toc-text">实验名称</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="toc-number">1.2.</span> <span class="toc-text">实验目的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="toc-number">1.3.</span> <span class="toc-text">实验环境</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9"><span class="toc-number">2.</span> <span class="toc-text">实验内容</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1"><span class="toc-number">2.1.</span> <span class="toc-text">实验方案设计</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="toc-number">2.2.</span> <span class="toc-text">实验结果分析</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">实验总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#jieba%E5%88%86%E8%AF%8D"><span class="toc-number">3.1.</span> <span class="toc-text">jieba 分词</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#word2vec"><span class="toc-number">3.2.</span> <span class="toc-text">Word2Vec</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pca"><span class="toc-number">3.3.</span> <span class="toc-text">PCA</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/Undergraduate-computer-course/nlp/%E8%AF%8D%E5%90%91%E9%87%8F/" rel="bookmark" title="词向量">词向量</a></li><li><a href="/Undergraduate-computer-course/nlp/review/" rel="bookmark" title="review">review</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="おうじせん" data-src="/images/touxiang.jpg"><p class="name" itemprop="name">おうじせん</p><div class="description" itemprop="description">誰よりスキだから</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">24</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">14</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">4</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL29zYWthbmEzNzM=" title="https:&#x2F;&#x2F;github.com&#x2F;osakana373"><i class="ic i-github"></i></span> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9XSFV3eng=" title="https:&#x2F;&#x2F;twitter.com&#x2F;WHUwzx"><i class="ic i-twitter"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvcGxheWxpc3Q/aWQ9Mzk5MDkyNDE2" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;playlist?id&#x3D;399092416"><i class="ic i-cloud-music"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/Undergraduate-computer-course/" title="分类于 计算机本科课程">计算机本科课程</a> <i class="ic i-angle-right"></i> <a href="/categories/Undergraduate-computer-course/OS/" title="分类于 操作系统">操作系统</a> <i class="ic i-angle-right"></i> <a href="/categories/Undergraduate-computer-course/OS/Oranges/" title="分类于 Oranges">Oranges</a></div><span><a href="/Undergraduate-computer-course/OS/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/" title="操作系统之内存管理">操作系统之内存管理</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Front-EndDevelopment/" title="分类于 前端开发">前端开发</a> <i class="ic i-angle-right"></i> <a href="/categories/Front-EndDevelopment/We-chat/" title="分类于 微信小程序">微信小程序</a></div><span><a href="/Front-EndDevelopment/We-chat/rich-text%E5%AF%8C%E6%96%87%E6%9C%AC%E6%A0%87%E7%AD%BE/" title="rich-text富文本标签">rich-text富文本标签</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Front-EndDevelopment/" title="分类于 前端开发">前端开发</a> <i class="ic i-angle-right"></i> <a href="/categories/Front-EndDevelopment/We-chat/" title="分类于 微信小程序">微信小程序</a></div><span><a href="/Front-EndDevelopment/We-chat/navigator%E5%AF%BC%E8%88%AA%E6%A0%87%E7%AD%BE/" title="navigator导航标签">navigator导航标签</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Front-EndDevelopment/" title="分类于 前端开发">前端开发</a> <i class="ic i-angle-right"></i> <a href="/categories/Front-EndDevelopment/We-chat/" title="分类于 微信小程序">微信小程序</a></div><span><a href="/Front-EndDevelopment/We-chat/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E4%B9%8Bswiper%E8%BD%AE%E6%92%AD%E5%9B%BE/" title="微信小程序之swiper轮播图">微信小程序之swiper轮播图</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Undergraduate-computer-course/" title="分类于 计算机本科课程">计算机本科课程</a> <i class="ic i-angle-right"></i> <a href="/categories/Undergraduate-computer-course/AI/" title="分类于 人工智能">人工智能</a> <i class="ic i-angle-right"></i> <a href="/categories/Undergraduate-computer-course/AI/nlp/" title="分类于 自然语言处理">自然语言处理</a></div><span><a href="/Undergraduate-computer-course/nlp/%E8%AF%8D%E5%90%91%E9%87%8F/" title="词向量">词向量</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Undergraduate-computer-course/" title="分类于 计算机本科课程">计算机本科课程</a> <i class="ic i-angle-right"></i> <a href="/categories/Undergraduate-computer-course/info-hiding/" title="分类于 信息隐藏技术">信息隐藏技术</a></div><span><a href="/Undergraduate-computer-course/info-hiding/VAE-Stega-Reading-Report/" title="VAE-Stega-Reading-Report">VAE-Stega-Reading-Report</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Front-EndDevelopment/" title="分类于 前端开发">前端开发</a> <i class="ic i-angle-right"></i> <a href="/categories/Front-EndDevelopment/We-chat/" title="分类于 微信小程序">微信小程序</a></div><span><a href="/Front-EndDevelopment/We-chat/%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/" title="生命周期">生命周期</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/French/" title="分类于 法语">法语</a> <i class="ic i-angle-right"></i> <a href="/categories/French/grammar/" title="分类于 法语语法">法语语法</a></div><span><a href="/French/grammar/french-grammar-29-32/french-grammar-29-32/" title="french-grammar-29-32">french-grammar-29-32</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/French/" title="分类于 法语">法语</a> <i class="ic i-angle-right"></i> <a href="/categories/French/grammar/" title="分类于 法语语法">法语语法</a></div><span><a href="/French/grammar/french-grammar-9-12/french-grammar-9-12/" title="french-grammar-9-12">french-grammar-9-12</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/Front-EndDevelopment/" title="分类于 前端开发">前端开发</a> <i class="ic i-angle-right"></i> <a href="/categories/Front-EndDevelopment/We-chat/" title="分类于 微信小程序">微信小程序</a></div><span><a href="/Front-EndDevelopment/We-chat/button%E6%8C%89%E9%92%AE/" title="button按钮">button按钮</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2021 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">おうじせん @ OSAKANA</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">83k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">1:16</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"Undergraduate-computer-course/nlp/词向量/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->